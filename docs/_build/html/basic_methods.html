
<!DOCTYPE html>

<html lang="english">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How to Use InfoTopo &#8212; infotopo 0.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="how-to-use-infotopo">
<h1>How to Use InfoTopo<a class="headerlink" href="#how-to-use-infotopo" title="Permalink to this headline">¶</a></h1>
<p>Infotopo is a general Machine Learning set of tools gathering Topology
(Cohomology and Homotopy), statistics and information theory
(information quantifies statistical structures generically) and
statistical physics.
It provides a matheamticaly formalised expression of deep network and learning,
and propose anuspervised or supervised learning mode (as a special case of the first).</p>
<p>The raw methods are computationnally consuming due to the intrinsic combinatorial
nature of the topological tools, even in the simplest case of a simplicial case
(the general case is based on the much broader partition combinatorics) the
computational complexity is of the order of 2 at the power n.
As a consequence, an important part of the tools and methods are dedicated
to overcome this extensive computation. Among the possible strategies and
heuristics used or currently developped, are:
_ restrict to simplicial cohomology and combinatorics (done here).
_ possible exploration of only the low dimensional structures (done here).
_ possible exploration of only most or least informative paths (done here).
_ possible restriction 2nd degree-dimension statistical interactions:
what is computed here is the equivalent of the Cech complex (with all degree-
dimension computed), and such restriction is equivalent to computing the Vietoris-Rips
complex (in development).
_ compute on GPU (in development).
As a result, for this 0.1 version of the software, and for computation with
commercial average PC, we recommand to analyse up to 20 variables (or dimensions)
at a time in the raw brut-force approach (see performance section).</p>
<p>We now present some basic example of use, inspiring our presentation from
the remarkable presentation of <a class="reference external" href="https://umap-learn.readthedocs.io/en/latest/">UMAP by McInnes.</a>
We first import some few tools: some of the datasets available in sklearn, seaborn to
visualise the results, and pandas to handle the data.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span><span class="p">,</span> <span class="n">load_digits</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">timeit</span>
</pre></div>
</div>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="s1">&#39;notebook&#39;</span><span class="p">,</span> <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mi">14</span><span class="p">,</span><span class="mi">10</span><span class="p">)})</span>
</pre></div>
</div>
<div class="section" id="iris-data">
<h2>Iris data<a class="headerlink" href="#iris-data" title="Permalink to this headline">¶</a></h2>
<p>The first example of dataset application we will present is the <a class="reference external" href="https://en.wikipedia.org/wiki/Iris_flower_data_set">iris
dataset</a>. It is
a very small dataset composed of 4 Random-Variables or dimensions that
quantify various petals and sepals observables of 3 different species of
Iris flowers, like petal length, for 150 flowers or points (50 for each
species). In the context of Infotopo it means that dimension_tot = 4
and sample_size = 150 (we consider all the points), and as the dimension
of the data set is small we will make the complete analysis of the
simplicial structure of dependencies by setting the maximum dimension
of analysis to dimension_max = dimension_tot. We also set the other
parameters of infotopo to approriate, as further explained.
We can load the iris dataset from sklearn.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">iris_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">DESCR</span><span class="p">)</span>

<span class="n">dimension_max</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">dimension_tot</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">sample_size</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">nb_of_values</span> <span class="o">=</span><span class="mi">9</span>
<span class="n">forward_computation_mode</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">work_on_transpose</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">supervised_mode</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">sampling_mode</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">deformed_probability_mode</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Iris Plants Database
====================

Notes
-----
Data Set Characteristics:
    :Number of Instances: 150 (50 in each of three classes)
    :Number of Attributes: 4 numeric, predictive attributes and the class
    :Attribute Information:
        - sepal length in cm
        - sepal width in cm
        - petal length in cm
        - petal width in cm
        - class:
                - Iris-Setosa
                - Iris-Versicolour
                - Iris-Virginica
    :Summary Statistics:

    ============== ==== ==== ======= ===== ====================
                    Min  Max   Mean    SD   Class Correlation
    ============== ==== ==== ======= ===== ====================
    sepal length:   4.3  7.9   5.84   0.83    0.7826
    sepal width:    2.0  4.4   3.05   0.43   -0.4194
    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)
    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)
    ============== ==== ==== ======= ===== ====================

    :Missing Attribute Values: None
    :Class Distribution: 33.3% for each of 3 classes.
    :Creator: R.A. Fisher
    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)
    :Date: July, 1988

This is a copy of UCI ML iris datasets.
http://archive.ics.uci.edu/ml/datasets/Iris

The famous Iris database, first used by Sir R.A Fisher

This is perhaps the best known database to be found in the
pattern recognition literature.  Fisher&#39;s paper is a classic in the field and
is referenced frequently to this day.  (See Duda &amp; Hart, for example.)  The
data set contains 3 classes of 50 instances each, where each class refers to a
type of iris plant.  One class is linearly separable from the other 2; the
latter are NOT linearly separable from each other.

References
----------
   - Fisher,R.A. &quot;The use of multiple measurements in taxonomic problems&quot;
     Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to
     Mathematical Statistics&quot; (John Wiley, NY, 1950).
   - Duda,R.O., &amp; Hart,P.E. (1973) Pattern Classification and Scene Analysis.
     (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.
   - Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System
     Structure and Classification Rule for Recognition in Partially Exposed
     Environments&quot;.  IEEE Transactions on Pattern Analysis and Machine
     Intelligence, Vol. PAMI-2, No. 1, 67-71.
   - Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;.  IEEE Transactions
     on Information Theory, May 1972, 431-433.
   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al&quot;s AUTOCLASS II
     conceptual clustering system finds 3 classes in the data.
   - Many, many more ...
</pre></div>
</div>
<p>As visualizing data in 4 dimensions or more is hard or not possible, we can first
plot all the pairwise scatterplot matrix to present the pairwise correlations and
dependencies between the variables, using Seaborn and pandas dataframe.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">iris_df</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">)))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">iris_df</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;species&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="_images/iris_pairwise_scatter.png" src="_images/iris_pairwise_scatter.png" />
<p>All those 2D views gives a rought but misleading idea of what the data looks
like in high dimension since, as we will see, some fully emergent
statistical dependences (synergic) can appear in higher dimension which are
totally unobservable in those 2D views. However such 2D views gives a fair
visual estimation of how much each pairs of variale covary, the correlation
coefficient and its generalization to non-linear relations, the pairwise
Mutual Information (I2). In topological Data Analysis terms, it gives rought
idea of what the skeleton of a Vietoris-Rips (information or correlation) complex
of the data could be.
We will see how to go beyond this pairwise statistical interaction case, and how
we can unravel some purely emergent higher dimensional interations. Along this
way, we will see how to compute and estimate all classical information functions,
multivariate Entropies, Mutual Informations and Conditional Entropies and
Mutual Informations.</p>
<p>To use infotopo we need to first construct a infotopo object from
the infotopo package. This makes a lot of same word, information is a
functor, a kind of general application or map, that could be either a
function or a class. So let's first import the infotopo library, we a set
of specifications of the parametters (cf. section parameters, some of them
like dimension_max = dimension_tot and sample_size have been fixed
previously to the size of the data input matrix).</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">infotopo</span>
</pre></div>
</div>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">information_topo</span> <span class="o">=</span> <span class="n">infotopo</span><span class="o">.</span><span class="n">infotopo</span><span class="p">(</span><span class="n">dimension_max</span> <span class="o">=</span> <span class="n">dimension_max</span><span class="p">,</span>
                            <span class="n">dimension_tot</span> <span class="o">=</span> <span class="n">dimension_tot</span><span class="p">,</span>
                            <span class="n">sample_size</span> <span class="o">=</span> <span class="n">sample_size</span><span class="p">,</span>
                            <span class="n">work_on_transpose</span> <span class="o">=</span> <span class="n">work_on_transpose</span><span class="p">,</span>
                            <span class="n">nb_of_values</span> <span class="o">=</span> <span class="n">nb_of_values</span><span class="p">,</span>
                            <span class="n">sampling_mode</span> <span class="o">=</span> <span class="n">sampling_mode</span><span class="p">,</span>
                            <span class="n">deformed_probability_mode</span> <span class="o">=</span> <span class="n">deformed_probability_mode</span><span class="p">,</span>
                            <span class="n">supervised_mode</span> <span class="o">=</span> <span class="n">supervised_mode</span><span class="p">,</span>
                            <span class="n">forward_computation_mode</span> <span class="o">=</span> <span class="n">forward_computation_mode</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we will compute all the simplicial semi-lattice of marginal and joint-entropy,
that contains 2 power n elements including the unit 0 reference measure element
The figure below give the usual Venn diagrams representation of set theoretic unions
and the corresponding semi-lattice of joint Random Variables and Joint Entropies, together
with its correponding simplicial representation, for 3 (top) and 4 variables-dimension
(bottom, the case of the iris dataset with 2 power 4 joint random variables). The edges of
the lattice are in one to one correspondence with conditional entropies.</p>
<img alt="_images/figure_lattice.png" src="_images/figure_lattice.png" />
<p>To do this we will call simplicial_entropies_decomposition, that gives in output
all the joint entropies in the form of a dictionary with keys given by the tuple of
the joint variables (ex: (1,3,4)) and  with values the joint or marginal entropy in bit
(presented below).</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">Nentropie</span> <span class="o">=</span> <span class="n">information_topo</span><span class="o">.</span><span class="n">simplicial_entropies_decomposition</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{(</span><span class="mi">4</span><span class="p">,):</span> <span class="mf">2.9528016441309237</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,):</span> <span class="mf">2.4902608474907497</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,):</span> <span class="mf">2.5591245822618114</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,):</span> <span class="mf">2.8298425472847066</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span> <span class="mf">3.983309507504916</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span> <span class="mf">4.798319817958397</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span> <span class="mf">4.83234271597051</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span> <span class="mf">4.437604597473526</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span> <span class="mf">4.2246575340121835</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span> <span class="mf">4.921846615158947</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span> <span class="mf">5.561696151051504</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span> <span class="mf">5.426426190681815</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span> <span class="mf">6.063697650692486</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span> <span class="mf">5.672729631265195</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span> <span class="mf">6.372515544003377</span><span class="p">}</span>
</pre></div>
</div>
<p>The result is an array with 150 samples, but only two feature columns
(instead of the four we started with). This is because, by default, UMAP
reduces down to 2D. Each row of the array is a 2-dimensional
representation of the corresponding flower. Thus we can plot the
<code class="docutils literal notranslate"><span class="pre">embedding</span></code> as a standard scatterplot and color by the target array
(since it applies to the transformed data which is in the same order as
the original).</p>
<p>This concludes our introduction to basic infotopo usage -- hopefully this
has given you the tools to get started for yourself. Further tutorials,
covering infotopo parameters and more advanced usage are also available when
you wish to dive deeper.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="quit().html">infotopo</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="quit().html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, pierre baudot.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.1.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/basic_methods.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>